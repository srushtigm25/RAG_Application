ğŸ“Œ Overview

RAG_Application is an end-to-end project that demonstrates how to build a Retrieval-Augmented Generation (RAG) pipeline to extract structured insights from PDF documents using LangChain, OpenAI embeddings, Chroma vector database, and a Streamlit UI.

It covers every step â€” from reading and chunking PDFs, creating embeddings, storing them in a vector database, querying via an LLM, and displaying results interactively.



ğŸš€ Key Features

ğŸ“„ PDF Parsing & Chunking â€“ Load and split large PDFs into coherent text segments.

ğŸ§© Embedding Generation â€“ Use OpenAI embeddings to convert text chunks into dense vector representations.

ğŸ’¾ Vector Database (Chroma) â€“ Store and retrieve embeddings efficiently using similarity search.

ğŸ¤– Context-Aware Question Answering â€“ Query PDFs via LangChainâ€™s retriever + ChatOpenAI.

ğŸ’¬ Streamlit Frontend â€“ Interactive interface for document upload and Q&A.

ğŸ³ Docker Support â€“ Easily containerize and deploy anywhere.



ğŸ—ï¸ Architecture
'''
PDF Document
â”‚
â–¼
[Document Loader]
â”‚
â–¼
[RecursiveCharacterTextSplitter]
â”‚
â–¼
[OpenAI Embeddings]
â”‚
â–¼
[Chroma Vector Store]
â”‚
â–¼
[Retriever + LLM (ChatOpenAI)]
â”‚
â–¼
Structured / Natural-Language Response
'''


ğŸ§° Tech Stack
Component	Technology
Language	Python 3.11
Frameworks	LangChain (Core, Community, OpenAI), Streamlit
Vector Store	Chroma
LLM Provider	OpenAI
Containerization	Docker
Environment Management	.env + python-dotenv


ğŸ”‘ Setup Instructions
1ï¸âƒ£ Clone the repository
git clone https://github.com/srushtigm25/RAG_Application.git
cd RAG_Application

2ï¸âƒ£ Create and activate a virtual environment
python3.11 -m venv .venv
source .venv/bin/activate

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

4ï¸âƒ£ Add your API key

Create a .env file in the project root:

OPENAI_API_KEY=your_openai_api_key_here

5ï¸âƒ£ Run the Streamlit app
streamlit run streamlit_app.py


Then open http://localhost:8501
 in your browser.

ğŸ³ Run with Docker
docker build -t rag_app .
docker run -p 8501:8501 rag_app

ğŸ§  How It Works

Upload a PDF via the Streamlit app.

The document is split into smaller semantic chunks.

Each chunk is converted into embeddings using OpenAIEmbeddings.

Chunks are stored in a Chroma vector database.

On query, the retriever finds the most similar chunks.

These chunks are passed to ChatOpenAI, which generates a structured or natural-language response.

ğŸ“Š Example Queries

â€œWhat is the title of the research paper?â€

â€œSummarize the abstract.â€

â€œList all datasets or methods mentioned.â€

â€œWhat is the conclusion of the paper?â€

ğŸ§© Future Enhancements

âœ… Multi-file PDF ingestion

âœ… Metadata extraction (tables, figures)

âœ… Support for other LLM providers (Claude, Gemini, Azure OpenAI)

âœ… Evaluation metrics for RAG quality
